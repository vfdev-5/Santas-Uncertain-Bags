{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning tryouts on Santa's uncertain bags\n",
    "\n",
    "## States \n",
    "\n",
    "A state is characterized by a matrix of size `(N_BAGS, N_TYPES)`. For example, `s[0,:]=[1,0,1,0,0,0,0,0,0]`. The initial state is when the matrix is null or a customly defined. Terminal states are defined by state's score. \n",
    "\n",
    "How many state there are? There are at most `N_BAGS * 9^10` states.\n",
    "\n",
    "\n",
    "## Actions\n",
    "\n",
    "Action is to add a toy following the list of available toys.\n",
    "\n",
    "\n",
    "## Rewards\n",
    "\n",
    "Action reward can be defined by the score of the bag where a toy has been added.\n",
    "\n",
    "\n",
    "## Q-learning: Off-Policy Temporal Difference Control\n",
    "\n",
    "In this algorithm we estimate action-value function $Q(s,a)$ as :\n",
    "$$\n",
    "Q(S_t,A_t) \\leftarrow Q(S_t,A_t) + \\alpha \\left[ R_{t+1} + \\gamma \\max_{a} Q(S_{t+1}, a) - Q(S_t,A_t) \\right], \\, Q(\\cal{S}^{+},a)=0\n",
    "$$\n",
    "\n",
    "**Algorithm**\n",
    "<br>\n",
    "<div style=\"background-color: #aaaaaa; padding: 10px; width: 75%; border: solid black; border-radius: 5px;\">\n",
    "\n",
    "    Initialize $Q(s, a)$, for all $s \\in \\cal{S}$, $a \\in \\cal{A}(s)$, arbitrarily, and $Q(\\text{terminal-state}, \\cdot) = 0$<br>\n",
    "    Repeat (for each episode):<br>\n",
    "    &emsp;Initialize $S$<br>\n",
    "    &emsp;Choose $A$ from $S$ using policy derived from $Q$ (e.g., $\\epsilon$-greedy)<br>\n",
    "    &emsp;Repeat (for each step of episode):<br>\n",
    "    &emsp;&emsp;Take action $A$, observe $R$, $S'$<br>\n",
    "    &emsp;&emsp;$Q(S,A) \\leftarrow Q(S,A) + \\alpha \\left[ R + \\gamma \\max_{a}Q(S', a) - Q(S,A) \\right]$<br>\n",
    "    &emsp;&emsp;$S \\leftarrow S'; \\, A \\leftarrow A';$<br>\n",
    "    &emsp;until $S$ is terminal\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../common')\n",
    "from utils import weight3 as weight_fn, weight_by_index\n",
    "from utils import bag_weight, score\n",
    "from utils import MAX_WEIGHT, AVAILABLE_GIFTS, GIFT_TYPES, N_TYPES, N_BAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REJECTED_BAGS_THRESHOLD = 0.1\n",
    "NEGATIVE_REWARD = -1000\n",
    "POSITIVE_REWARD = 1000\n",
    "\n",
    "def step_reward(rejected):    \n",
    "    return 0.0 if rejected < REJECTED_BAGS_THRESHOLD else -rejected*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000.0\n"
     ]
    }
   ],
   "source": [
    "initial_state = np.zeros((N_BAGS, N_TYPES), dtype=np.uint8)\n",
    "alpha = 0.72\n",
    "goal_weight = MAX_WEIGHT * N_BAGS * alpha\n",
    "\n",
    "print goal_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_action = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_action(state, action):\n",
    "    new_state = state.copy()\n",
    "    new_state[action[0], action[1]] += 1\n",
    "    return new_state\n",
    "\n",
    "def is_available(state, available_gifts, gift_types=GIFT_TYPES):\n",
    "    sum_gifts = np.sum(np.array(state), axis=0)\n",
    "    for v, gift_type in zip(sum_gifts, gift_types):\n",
    "        if available_gifts[gift_type] - v < 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def update_available_gifts(available_gifts, state, gift_types=GIFT_TYPES):\n",
    "    sum_gifts = np.sum(np.array(state), axis=0)\n",
    "    for v, gift_type in zip(sum_gifts, gift_types):\n",
    "        assert available_gifts[gift_type] - v >= 0, \"Found state is not available : {}, {}\".format(state, available_gifts)\n",
    "        available_gifts[gift_type] = available_gifts[gift_type] - v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]] 1.91990057321 True 0.0\n",
      "(15, 6)\n"
     ]
    }
   ],
   "source": [
    "new_state = take_action(initial_state, example_action)\n",
    "new_score, rejected = score(new_state, return_rejected=True)\n",
    "print new_state, new_score, is_available(new_state, AVAILABLE_GIFTS), step_reward(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def state_to_str(state):\n",
    "    return state.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heapq??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "heap = []\n",
    "\n",
    "heapq.heappush(heap, [(0, 0), 1])\n",
    "heapq.heappush(heap, [(0, 1), 10])\n",
    "heapq.heappush(heap, [(12, 5), 3])\n",
    "\n",
    "\n",
    "# sorted([[(0, 0), 1], [(0, 1), 10], [(12, 5), 3]], key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0), 1], [(0, 1), 10], [(12, 5), 3]]\n"
     ]
    }
   ],
   "source": [
    "print heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def get_policy_action(state, action_value_function, epsilon=0.1):\n",
    "    state_key = state_to_str(state)\n",
    "    u = np.random.rand()\n",
    "    if state_key in action_value_function and u > epsilon:\n",
    "        \n",
    "        actions_values = action_value_function[state_key]\n",
    "        actions_values = sorted(actions_values, key=itemgetter(1), reverse=True)\n",
    "        return actions_values[0][0]    \n",
    "    else:\n",
    "        # Arbitrary initialization\n",
    "        bag_id = np.random.randint(N_BAGS)\n",
    "        toy_id = np.random.randint(N_TYPES)\n",
    "        action = (bag_id, toy_id)\n",
    "        value = np.random.rand()\n",
    "        action_value_function[state_key].append([action, value])\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-a1b52de73bb4>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-a1b52de73bb4>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    n_episodes=10, alpha=0.75, gamma=0.7, epsilon=0.001, action_value_function=None):\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def q_learning(goal_weight, \n",
    "               available_gifts,\n",
    "               initial_state=None\n",
    "               n_episodes=10, alpha=0.75, gamma=0.7, epsilon=0.001, action_value_function=None):\n",
    "    \n",
    "    for i in range(n_episodes):\n",
    "\n",
    "        episode_length = N_BAGS * N_TYPES * 10\n",
    "        state = np.zeros((N_BAGS, N_TYPES)) if initial_state is None else initial_state        \n",
    "        action = get_policy_action(state, action_value_function, epsilon=epsilon)\n",
    "        state_score = score(state)\n",
    "        is_terminal = state_score > goal_weight and is_available(state, available_gifts)\n",
    "        while not is_terminal:\n",
    "            \n",
    "            episode_length -= 1 \n",
    "            if episode_length < 0:\n",
    "                logging.warn('Episode length is reached, but state score is still : %f / %f' % (state_score, goal_weight))\n",
    "                break\n",
    "            \n",
    "            #print \"state, action : \", state, action\n",
    "            current_reward = 0 \n",
    "            new_state = take_action(state, action)\n",
    "            new_score, rejected = score(new_state, return_rejected=True)\n",
    "            \n",
    "            if not is_available(new_state, available_gifts):                \n",
    "                current_reward = NEGATIVE_REWARD\n",
    "                is_terminal = True\n",
    "            elif new_score >= goal_weight:\n",
    "                current_reward = POSITIVE_REWARD\n",
    "                is_terminal = True\n",
    "            elif new_score < goal_weight:\n",
    "                current_reward = step_reward(rejected)\n",
    "            else:\n",
    "                raise Exception(\"Unclassified state: {}, score={}\".format(new_state, new_score))\n",
    "                            \n",
    "            # Update Q(s,a)\n",
    "            actions_values = \n",
    "            v = action_value_function[y, x, action_index]\n",
    "            nv = np.max(action_value_function[ny, nx, :])\n",
    "            t = alpha * (current_reward + gamma * nv - v) \n",
    "            action_value_function[y, x, action_index] += t            \n",
    "            \n",
    "            state = new_state\n",
    "            action = get_policy_action(state, action_value_function, epsilon=epsilon)                        \n",
    "                \n",
    "    return policy, action_value_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
